{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e70cf1a-6fb9-43b7-b884-00ce34b62d62",
   "metadata": {},
   "source": [
    "# N225 Japan Index trading\n",
    "\n",
    "### Due to CUDA support I'm editing this notebook at google colab - I'll refresh this notebook when I'll get some results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187eb5dd-4fe5-4f9b-b23e-15273cfdb121",
   "metadata": {},
   "source": [
    "### Import dependecies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2029dffa-3829-4442-841f-b860ba9b96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_anytrading\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "from finta import TA\n",
    "from gym_anytrading.envs import StocksEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "import os\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecc96a-7a2e-45b5-83b2-285b0856d2f0",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749a14df-29ec-4983-9be9-ecd85c46711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/N225.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed33073-8300-4252-b41b-63f02fe4c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73781f8c-b131-4324-8771-8061e8de2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df['RSI'] = TA.RSI(df)\n",
    "df['SMA'] = TA.SMA(df,14)\n",
    "df['ATR'] = TA.ATR(df)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45c7b7d-de08-41ea-9040-cdf59ef5d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your financial data into a DataFrame (replace with your own data)\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Calculate the top 20 technical analysis metrics\n",
    "sma = TA.SMA(df,20)\n",
    "ema = TA.EMA(df,20)\n",
    "rsi = TA.RSI(df,14)\n",
    "macd = TA.MACD(df)\n",
    "upper, mid, lower = TA.BBANDS(df)\n",
    "atr = TA.ATR(df)\n",
    "stoch = TA.STOCH(df)\n",
    "cci = TA.CCI(df)\n",
    "roc = TA.ROC(df)\n",
    "obv = TA.OBV(df)\n",
    "adx = TA.ADX(df)\n",
    "# cmf = TA.CMF(df)\n",
    "uo = TA.UO(df)\n",
    "wr = TA.WILLIAMS(df)\n",
    "# sar = TA.PSAR(df)\n",
    "# upper, mid, lower = TA.MAE(df['Close'], period=20, percent=0.1)\n",
    "# conversion_line, base_line, leading_span_A, leading_span_B, lagging_span = TA.ICHIMOKU(df['High'], df['Low'])\n",
    "adx = TA.ADX(df)\n",
    "mfi = TA.MFI(df)\n",
    "# co = TA.CHO(df)\n",
    "# Combine all the metrics into a single DataFrame\n",
    "all_metrics_df= pd.DataFrame({\n",
    "    'SMA': sma,\n",
    "    'EMA': ema,\n",
    "    'RSI': rsi,\n",
    "    'MACD': macd.MACD,\n",
    "    'MACD_SIGNAL' : macd.SIGNAL,\n",
    "    # # 'BBANDS_Upper': upper,\n",
    "    # # 'BBANDS_Mid': mid,\n",
    "    # # 'BBANDS_Lower': lower,\n",
    "    'ATR': atr,\n",
    "    'Stochastic': stoch,\n",
    "    'CCI': cci,\n",
    "    'ROC': roc,\n",
    "    'OBV': obv,\n",
    "    'ADX': adx,\n",
    "    'UO': uo,\n",
    "    'Williams %R': wr,\n",
    "    'MFI': mfi\n",
    "})\n",
    "\n",
    "# Display the DataFrame with all the calculated metrics\n",
    "# print(all_metrics_df.tail())\n",
    "df = df.merge(all_metrics_df, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad42ae4-9059-4a44-8243-6b8b5d7d11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9ecf54b-25d1-4968-9960-d2bc21c7d9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SMA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>...</th>\n",
       "      <th>MACD_SIGNAL</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Stochastic</th>\n",
       "      <th>CCI</th>\n",
       "      <th>ROC</th>\n",
       "      <th>OBV</th>\n",
       "      <th>ADX</th>\n",
       "      <th>UO</th>\n",
       "      <th>Williams %R</th>\n",
       "      <th>MFI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2002-06-10</td>\n",
       "      <td>11470.919922</td>\n",
       "      <td>11522.040039</td>\n",
       "      <td>11370.209961</td>\n",
       "      <td>11370.209961</td>\n",
       "      <td>11370.209961</td>\n",
       "      <td>37900000.0</td>\n",
       "      <td>11753.107617</td>\n",
       "      <td>11669.727093</td>\n",
       "      <td>38.333146</td>\n",
       "      <td>...</td>\n",
       "      <td>64.023418</td>\n",
       "      <td>161.052176</td>\n",
       "      <td>0.642566</td>\n",
       "      <td>-150.917930</td>\n",
       "      <td>-5.088876</td>\n",
       "      <td>-3.790000e+07</td>\n",
       "      <td>15.009696</td>\n",
       "      <td>31.336232</td>\n",
       "      <td>-99.357434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2002-06-11</td>\n",
       "      <td>11390.410156</td>\n",
       "      <td>11514.530273</td>\n",
       "      <td>11390.410156</td>\n",
       "      <td>11449.440430</td>\n",
       "      <td>11449.440430</td>\n",
       "      <td>39600000.0</td>\n",
       "      <td>11757.770117</td>\n",
       "      <td>11648.747411</td>\n",
       "      <td>42.131889</td>\n",
       "      <td>...</td>\n",
       "      <td>46.922613</td>\n",
       "      <td>157.344308</td>\n",
       "      <td>11.711066</td>\n",
       "      <td>-140.988668</td>\n",
       "      <td>-4.399027</td>\n",
       "      <td>1.700000e+06</td>\n",
       "      <td>15.911485</td>\n",
       "      <td>33.130199</td>\n",
       "      <td>-88.288934</td>\n",
       "      <td>51.163721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2002-06-12</td>\n",
       "      <td>11392.320313</td>\n",
       "      <td>11405.290039</td>\n",
       "      <td>11261.929688</td>\n",
       "      <td>11327.059570</td>\n",
       "      <td>11327.059570</td>\n",
       "      <td>42800000.0</td>\n",
       "      <td>11741.974609</td>\n",
       "      <td>11618.110474</td>\n",
       "      <td>38.215927</td>\n",
       "      <td>...</td>\n",
       "      <td>28.906272</td>\n",
       "      <td>164.810058</td>\n",
       "      <td>7.947515</td>\n",
       "      <td>-170.774592</td>\n",
       "      <td>-5.421435</td>\n",
       "      <td>-4.110000e+07</td>\n",
       "      <td>17.296391</td>\n",
       "      <td>29.035529</td>\n",
       "      <td>-92.052485</td>\n",
       "      <td>33.068903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2002-06-13</td>\n",
       "      <td>11366.059570</td>\n",
       "      <td>11396.280273</td>\n",
       "      <td>11132.589844</td>\n",
       "      <td>11144.839844</td>\n",
       "      <td>11144.839844</td>\n",
       "      <td>46500000.0</td>\n",
       "      <td>11712.282080</td>\n",
       "      <td>11573.037080</td>\n",
       "      <td>33.259091</td>\n",
       "      <td>...</td>\n",
       "      <td>8.287444</td>\n",
       "      <td>170.743652</td>\n",
       "      <td>1.291050</td>\n",
       "      <td>-175.127639</td>\n",
       "      <td>-6.628979</td>\n",
       "      <td>-8.760000e+07</td>\n",
       "      <td>19.043530</td>\n",
       "      <td>26.369886</td>\n",
       "      <td>-98.708950</td>\n",
       "      <td>23.952292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2002-06-14</td>\n",
       "      <td>11121.889648</td>\n",
       "      <td>11127.160156</td>\n",
       "      <td>10911.070313</td>\n",
       "      <td>10920.629883</td>\n",
       "      <td>10920.629883</td>\n",
       "      <td>112800000.0</td>\n",
       "      <td>11665.947559</td>\n",
       "      <td>11510.903061</td>\n",
       "      <td>28.381171</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.477726</td>\n",
       "      <td>178.245047</td>\n",
       "      <td>0.919888</td>\n",
       "      <td>-201.328185</td>\n",
       "      <td>-7.866111</td>\n",
       "      <td>-2.004000e+08</td>\n",
       "      <td>21.289411</td>\n",
       "      <td>24.699603</td>\n",
       "      <td>-99.080112</td>\n",
       "      <td>14.476512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>2022-10-19</td>\n",
       "      <td>27225.169922</td>\n",
       "      <td>27371.380859</td>\n",
       "      <td>27192.789063</td>\n",
       "      <td>27257.380859</td>\n",
       "      <td>27257.380859</td>\n",
       "      <td>57600000.0</td>\n",
       "      <td>26788.177637</td>\n",
       "      <td>26981.848025</td>\n",
       "      <td>52.141919</td>\n",
       "      <td>...</td>\n",
       "      <td>-265.755798</td>\n",
       "      <td>451.986467</td>\n",
       "      <td>92.020801</td>\n",
       "      <td>80.498043</td>\n",
       "      <td>5.089868</td>\n",
       "      <td>3.389630e+10</td>\n",
       "      <td>20.211269</td>\n",
       "      <td>53.056735</td>\n",
       "      <td>-7.979199</td>\n",
       "      <td>58.239109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>26981.750000</td>\n",
       "      <td>27092.550781</td>\n",
       "      <td>26872.449219</td>\n",
       "      <td>27006.960938</td>\n",
       "      <td>27006.960938</td>\n",
       "      <td>60300000.0</td>\n",
       "      <td>26754.104688</td>\n",
       "      <td>26984.239731</td>\n",
       "      <td>49.172671</td>\n",
       "      <td>...</td>\n",
       "      <td>-241.779195</td>\n",
       "      <td>459.146624</td>\n",
       "      <td>77.930327</td>\n",
       "      <td>44.553721</td>\n",
       "      <td>3.017921</td>\n",
       "      <td>3.383600e+10</td>\n",
       "      <td>19.136114</td>\n",
       "      <td>58.038876</td>\n",
       "      <td>-22.069673</td>\n",
       "      <td>51.151423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>26903.500000</td>\n",
       "      <td>26985.380859</td>\n",
       "      <td>26869.380859</td>\n",
       "      <td>26890.580078</td>\n",
       "      <td>26890.580078</td>\n",
       "      <td>56300000.0</td>\n",
       "      <td>26732.977149</td>\n",
       "      <td>26975.319764</td>\n",
       "      <td>47.810046</td>\n",
       "      <td>...</td>\n",
       "      <td>-220.845014</td>\n",
       "      <td>424.940848</td>\n",
       "      <td>71.381881</td>\n",
       "      <td>36.999466</td>\n",
       "      <td>-0.376519</td>\n",
       "      <td>3.377970e+10</td>\n",
       "      <td>18.143420</td>\n",
       "      <td>57.668017</td>\n",
       "      <td>-28.618119</td>\n",
       "      <td>53.347422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>27233.000000</td>\n",
       "      <td>27308.970703</td>\n",
       "      <td>26974.900391</td>\n",
       "      <td>26974.900391</td>\n",
       "      <td>26974.900391</td>\n",
       "      <td>59100000.0</td>\n",
       "      <td>26724.030664</td>\n",
       "      <td>26975.279823</td>\n",
       "      <td>48.914594</td>\n",
       "      <td>...</td>\n",
       "      <td>-201.066539</td>\n",
       "      <td>411.834542</td>\n",
       "      <td>63.479068</td>\n",
       "      <td>69.634179</td>\n",
       "      <td>-0.536969</td>\n",
       "      <td>3.383880e+10</td>\n",
       "      <td>17.144169</td>\n",
       "      <td>54.334131</td>\n",
       "      <td>-36.520932</td>\n",
       "      <td>52.436766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>2022-10-25</td>\n",
       "      <td>27113.199219</td>\n",
       "      <td>27337.800781</td>\n",
       "      <td>27073.179688</td>\n",
       "      <td>27250.279297</td>\n",
       "      <td>27250.279297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26764.967090</td>\n",
       "      <td>27001.470249</td>\n",
       "      <td>52.453729</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.197477</td>\n",
       "      <td>382.138114</td>\n",
       "      <td>87.182470</td>\n",
       "      <td>86.141504</td>\n",
       "      <td>-0.223429</td>\n",
       "      <td>3.383880e+10</td>\n",
       "      <td>16.278896</td>\n",
       "      <td>46.930876</td>\n",
       "      <td>-12.817530</td>\n",
       "      <td>47.643424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4989 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "634   2002-06-10  11470.919922  11522.040039  11370.209961  11370.209961   \n",
       "635   2002-06-11  11390.410156  11514.530273  11390.410156  11449.440430   \n",
       "636   2002-06-12  11392.320313  11405.290039  11261.929688  11327.059570   \n",
       "637   2002-06-13  11366.059570  11396.280273  11132.589844  11144.839844   \n",
       "638   2002-06-14  11121.889648  11127.160156  10911.070313  10920.629883   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "5706  2022-10-19  27225.169922  27371.380859  27192.789063  27257.380859   \n",
       "5707  2022-10-20  26981.750000  27092.550781  26872.449219  27006.960938   \n",
       "5708  2022-10-21  26903.500000  26985.380859  26869.380859  26890.580078   \n",
       "5709  2022-10-24  27233.000000  27308.970703  26974.900391  26974.900391   \n",
       "5710  2022-10-25  27113.199219  27337.800781  27073.179688  27250.279297   \n",
       "\n",
       "         Adj Close       Volume           SMA           EMA        RSI  ...  \\\n",
       "634   11370.209961   37900000.0  11753.107617  11669.727093  38.333146  ...   \n",
       "635   11449.440430   39600000.0  11757.770117  11648.747411  42.131889  ...   \n",
       "636   11327.059570   42800000.0  11741.974609  11618.110474  38.215927  ...   \n",
       "637   11144.839844   46500000.0  11712.282080  11573.037080  33.259091  ...   \n",
       "638   10920.629883  112800000.0  11665.947559  11510.903061  28.381171  ...   \n",
       "...            ...          ...           ...           ...        ...  ...   \n",
       "5706  27257.380859   57600000.0  26788.177637  26981.848025  52.141919  ...   \n",
       "5707  27006.960938   60300000.0  26754.104688  26984.239731  49.172671  ...   \n",
       "5708  26890.580078   56300000.0  26732.977149  26975.319764  47.810046  ...   \n",
       "5709  26974.900391   59100000.0  26724.030664  26975.279823  48.914594  ...   \n",
       "5710  27250.279297          0.0  26764.967090  27001.470249  52.453729  ...   \n",
       "\n",
       "      MACD_SIGNAL         ATR  Stochastic         CCI       ROC           OBV  \\\n",
       "634     64.023418  161.052176    0.642566 -150.917930 -5.088876 -3.790000e+07   \n",
       "635     46.922613  157.344308   11.711066 -140.988668 -4.399027  1.700000e+06   \n",
       "636     28.906272  164.810058    7.947515 -170.774592 -5.421435 -4.110000e+07   \n",
       "637      8.287444  170.743652    1.291050 -175.127639 -6.628979 -8.760000e+07   \n",
       "638    -16.477726  178.245047    0.919888 -201.328185 -7.866111 -2.004000e+08   \n",
       "...           ...         ...         ...         ...       ...           ...   \n",
       "5706  -265.755798  451.986467   92.020801   80.498043  5.089868  3.389630e+10   \n",
       "5707  -241.779195  459.146624   77.930327   44.553721  3.017921  3.383600e+10   \n",
       "5708  -220.845014  424.940848   71.381881   36.999466 -0.376519  3.377970e+10   \n",
       "5709  -201.066539  411.834542   63.479068   69.634179 -0.536969  3.383880e+10   \n",
       "5710  -178.197477  382.138114   87.182470   86.141504 -0.223429  3.383880e+10   \n",
       "\n",
       "            ADX         UO  Williams %R        MFI  \n",
       "634   15.009696  31.336232   -99.357434   0.000000  \n",
       "635   15.911485  33.130199   -88.288934  51.163721  \n",
       "636   17.296391  29.035529   -92.052485  33.068903  \n",
       "637   19.043530  26.369886   -98.708950  23.952292  \n",
       "638   21.289411  24.699603   -99.080112  14.476512  \n",
       "...         ...        ...          ...        ...  \n",
       "5706  20.211269  53.056735    -7.979199  58.239109  \n",
       "5707  19.136114  58.038876   -22.069673  51.151423  \n",
       "5708  18.143420  57.668017   -28.618119  53.347422  \n",
       "5709  17.144169  54.334131   -36.520932  52.436766  \n",
       "5710  16.278896  46.930876   -12.817530  47.643424  \n",
       "\n",
       "[4989 rows x 21 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33957c4a-a08c-4bb9-a757-7c1f1546f86f",
   "metadata": {},
   "source": [
    "### Creating my enviorment for AnyTrading, such that I can use 3 positions as actions (Short, Hold, Long) \n",
    "\n",
    "Here is the stanrd implementation of TradingEnv, I'm adding just the hold position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51cf3730-ef68-4a55-9a40-6e1309d3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(Enum):\n",
    "    Sell = 0\n",
    "    Hold = 1\n",
    "    Buy = 2\n",
    "\n",
    "\n",
    "class Positions(Enum):\n",
    "    Short = 0\n",
    "    Hold = 1\n",
    "    Long = 2\n",
    "    \n",
    "\n",
    "def opposite(position: Positions , action: int) -> any:\n",
    "    '''New opposite, so that it works with 3 actions, overwiev:\n",
    "            When action is Sell, we either Go to Hold (when we bought earlier) or short (when position was flat before)\n",
    "            \n",
    "            When action is Buy, we conduct the same reasoning but in the oppiste way\n",
    "\n",
    "            When the action is Hold we stay at current position\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    action = Actions(action)\n",
    "    if action == Actions.Sell:\n",
    "            \n",
    "        if position == Positions.Long:\n",
    "            return Positions.Hold, False\n",
    "        \n",
    "        if position == Positions.Hold:\n",
    "            return Positions.Short, True\n",
    "        \n",
    "        \n",
    "    if action == Actions.Buy:\n",
    "        if position == Positions.Short:\n",
    "            return Positions.Hold, False\n",
    "        \n",
    "        if position == Positions.Hold:\n",
    "            return Positions.Long, True\n",
    "        \n",
    "    return position, False\n",
    "        \n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df, window_size):\n",
    "        assert df.ndim == 2\n",
    "\n",
    "        self.seed()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        self.shape = (window_size, self.signal_features.shape[1])\n",
    "\n",
    "        # spaces\n",
    "        self.action_space = spaces.Discrete(len(Actions))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float64)\n",
    "\n",
    "        # episode\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.prices) - 1\n",
    "        self._done = None\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self._position = None\n",
    "        self._position_history = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        self._first_rendering = None\n",
    "        self.history = None\n",
    "\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self._done = False\n",
    "        self._current_tick = self._start_tick\n",
    "        self._last_trade_tick = self._current_tick - 1\n",
    "        self._position = Positions.Hold\n",
    "        self._position_history = (self.window_size * [None]) + [self._position]\n",
    "        self._total_reward = 0.\n",
    "        self._total_profit = 1.  # unit\n",
    "        self._first_rendering = True\n",
    "        self.history = {}\n",
    "        return self._get_observation()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        self._done = False\n",
    "        self._current_tick += 1\n",
    "\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._done = True\n",
    "\n",
    "        step_reward = self._calculate_reward(action)\n",
    "        self._total_reward += step_reward\n",
    "\n",
    "        self._update_profit(action)\n",
    "\n",
    "        self._position, trade = opposite(self._position, action)\n",
    "        if trade:\n",
    "            self._last_trade_tick = self._current_tick\n",
    "\n",
    "        self._position_history.append(self._position)\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "            position = self._position.value\n",
    "        )\n",
    "        self._update_history(info)\n",
    "\n",
    "        return observation, step_reward, self._done, info\n",
    "\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return self.signal_features[(self._current_tick-self.window_size+1):self._current_tick+1]\n",
    "\n",
    "\n",
    "    def _update_history(self, info):\n",
    "        if not self.history:\n",
    "            self.history = {key: [] for key in info.keys()}\n",
    "\n",
    "        for key, value in info.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "\n",
    "        def _plot_position(position, tick):\n",
    "            color = None\n",
    "            if position == Positions.Short:\n",
    "                color = 'red'\n",
    "            elif position == Positions.Long:\n",
    "                color = 'green'\n",
    "            elif position == Positions.Hold:\n",
    "                color = 'blue'\n",
    "            if color:\n",
    "                plt.scatter(tick, self.prices[tick], color=color)\n",
    "\n",
    "        if self._first_rendering:\n",
    "            self._first_rendering = False\n",
    "            plt.cla()\n",
    "            plt.plot(self.prices)\n",
    "            start_position = self._position_history[self._start_tick]\n",
    "            _plot_position(start_position, self._start_tick)\n",
    "\n",
    "        _plot_position(self._position, self._current_tick)\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "\n",
    "        plt.pause(0.01)\n",
    "\n",
    "\n",
    "    def render_all(self, mode='human'):\n",
    "        window_ticks = np.arange(len(self._position_history))\n",
    "        plt.plot(self.prices)\n",
    "\n",
    "        short_ticks = []\n",
    "        long_ticks = []\n",
    "        hold_ticks = [] \n",
    "        for i, tick in enumerate(window_ticks):\n",
    "            if self._position_history[i] == Positions.Short:\n",
    "                short_ticks.append(tick)\n",
    "            elif self._position_history[i] == Positions.Long:\n",
    "                long_ticks.append(tick)\n",
    "            elif self._position_history[i] == Positions.Hold:\n",
    "                hold_ticks.append(tick)\n",
    "\n",
    "        plt.plot(short_ticks, self.prices[short_ticks], 'ro')\n",
    "        plt.plot(hold_ticks, self.prices[hold_ticks], 'bo')\n",
    "        plt.plot(long_ticks, self.prices[long_ticks], 'go')\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def close(self):\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def save_rendering(self, filepath):\n",
    "        plt.savefig(filepath)\n",
    "\n",
    "\n",
    "    def pause_rendering(self):\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def _process_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def max_possible_profit(self):  # trade fees are ignored\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e81940-10c9-458f-86a0-3bc0cc57b5a1",
   "metadata": {},
   "source": [
    "#### StocksEnv\n",
    "\n",
    "Here I'm implementing StocksEnv such that it'll utilize Hold action also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b0c1ffb-aaae-40b4-aa61-57bd3dff8bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .trading_env import TradingEnv, Actions, Positions\n",
    "\n",
    "\n",
    "class StocksEnv(TradingEnv):\n",
    "\n",
    "    def __init__(self, df, window_size, frame_bound):\n",
    "        assert len(frame_bound) == 2\n",
    "\n",
    "        self.frame_bound = frame_bound\n",
    "        super().__init__(df, window_size)\n",
    "\n",
    "        self.trade_fee_bid_percent = 0.003  # unit\n",
    "        self.trade_fee_ask_percent = 0.003\n",
    "        # # unit\n",
    "        \n",
    "        # self.trade_fee_bid_percent = 0  # unit\n",
    "        # self.trade_fee_ask_percent = 0\n",
    "    def _process_data(self):\n",
    "        start = self.frame_bound[0] - self.window_size\n",
    "        end = self.frame_bound[1]\n",
    "        prices = self.df.loc[:,'Close'].to_numpy()[start:end]\n",
    "        signal_features = self.df.iloc[:,~df.columns.isin(['Date','Close'])].to_numpy()[start:end]\n",
    "        return prices, signal_features\n",
    "    \n",
    "#     def _process_data(self):\n",
    "#         prices = self.df.loc[:, 'Close'].to_numpy()\n",
    "\n",
    "#         prices[self.frame_bound[0] - self.window_size]  # validate index (TODO: Improve validation)\n",
    "#         prices = prices[self.frame_bound[0]-self.window_size:self.frame_bound[1]]\n",
    "\n",
    "#         diff = np.insert(np.diff(prices), 0, 0)\n",
    "#         signal_features = np.column_stack((prices, diff))\n",
    "\n",
    "#         return prices, signal_features\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        step_reward = 0\n",
    "        trade = True\n",
    "\n",
    "        if trade:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "            price_diff = current_price - last_trade_price\n",
    "\n",
    "            if self._position == Positions.Long:\n",
    "                step_reward += price_diff\n",
    "            elif self._position == Positions.Short:\n",
    "                step_reward += -price_diff \n",
    "\n",
    "        return step_reward\n",
    "\n",
    "    \n",
    "# Is this actually correct? reutrn for short shuld be different I suppouse\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        trade = True\n",
    "        \n",
    "        if trade or self._done:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "\n",
    "            if self._position == Positions.Long:\n",
    "                shares = (self._total_profit * (1 - self.trade_fee_ask_percent)) / last_trade_price\n",
    "                self._total_profit = (shares * (1 - self.trade_fee_bid_percent)) * current_price\n",
    "            elif self._position == Positions.Short:\n",
    "                self._total_profit = (self._total_profit *(1 + (last_trade_price - current_price - self.trade_fee_bid_percent*last_trade_price - self.trade_fee_ask_percent*current_price ) / last_trade_price))\n",
    "\n",
    "    def max_possible_profit(self):\n",
    "        current_tick = self._start_tick\n",
    "        last_trade_tick = current_tick - 1\n",
    "        profit = 1.\n",
    "\n",
    "        while current_tick <= self._end_tick:\n",
    "            position = None\n",
    "            if self.prices[current_tick] < self.prices[current_tick - 1]:\n",
    "                while (current_tick <= self._end_tick and\n",
    "                       self.prices[current_tick] < self.prices[current_tick - 1]):\n",
    "                    current_tick += 1\n",
    "                position = Positions.Short\n",
    "            else:\n",
    "                while (current_tick <= self._end_tick and\n",
    "                       self.prices[current_tick] >= self.prices[current_tick - 1]):\n",
    "                    current_tick += 1\n",
    "                position = Positions.Long\n",
    "\n",
    "            if position == Positions.Long:\n",
    "                current_price = self.prices[current_tick - 1]\n",
    "                last_trade_price = self.prices[last_trade_tick]\n",
    "                shares = profit / last_trade_price\n",
    "                profit = shares * current_price\n",
    "            last_trade_tick = current_tick - 1\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3acd3ea-1e79-4ca3-b10f-07ec2a846ea3",
   "metadata": {},
   "source": [
    "## Creating custom LSTM model for trading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4704e6-5e20-48d1-aa5a-b0fe799e6059",
   "metadata": {},
   "source": [
    "I create this custom model, becouse I assume, LSTM will work better then normal Neural net. \n",
    "\n",
    " Architecture of this model may change, depending on the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcad7d4a-8fc6-416e-8c48-a07d99c72b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLSTM(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm=nn.LSTM(input_size,hidden_size,num_layers=2,bidirectional= True)#,batch_first=True)\n",
    "        self.fully_connected=nn.Sequential(\n",
    "            nn.Linear(hidden_size*2,4048),\n",
    "            nn.BatchNorm1d(4048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(4048,2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256,output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        batch_size=x.shape[0]\n",
    "        h0=torch.zeros(2*2,self.hidden_size).cuda()\n",
    "        c0=torch.zeros(2*2,self.hidden_size).cuda()\n",
    "\n",
    "        lstm_output, cels = self.lstm(x,(h0,c0))\n",
    "        flatten_output=torch.flatten(lstm_output,start_dim=1)\n",
    "        \n",
    "        output=self.fully_connected(flatten_output)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8040b17-f2df-46af-8b73-3bf55e841bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "\n",
    "class CustomNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN)\n",
    "    :param last_layer_dim_pi: (int) number of units for the last layer of the policy network\n",
    "    :param last_layer_dim_vf: (int) number of units for the last layer of the value network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim: int,\n",
    "        last_layer_dim_pi: int = 128,\n",
    "        last_layer_dim_vf: int = 128,\n",
    "    ):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "\n",
    "        # IMPORTANT:\n",
    "        # Save output dimensions, used to create the distributions\n",
    "        self.latent_dim_pi = last_layer_dim_pi\n",
    "        self.latent_dim_vf = last_layer_dim_vf\n",
    "\n",
    "        # Policy network\n",
    "        # self.policy_net = nn.Sequential(\n",
    "        #     nn.Linear(feature_dim, last_layer_dim_pi), nn.ReLU()\n",
    "        # )\n",
    "        \n",
    "        self.policy_net = customLSTM(feature_dim,1024,last_layer_dim_pi)\n",
    "        # Value network\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(128,256), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(128,last_layer_dim_vf), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, features: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
    "        \"\"\"\n",
    "        :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network.\n",
    "            If all layers are shared, then ``latent_policy == latent_value``\n",
    "        \"\"\"\n",
    "        return self.policy_net(features), self.value_net(features)\n",
    "\n",
    "    def forward_actor(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.policy_net(features)\n",
    "\n",
    "    def forward_critic(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.value_net(features)\n",
    "\n",
    "\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: gym.spaces.Space,\n",
    "        action_space: gym.spaces.Space,\n",
    "        lr_schedule: Callable[[float], float],\n",
    "        net_arch: Optional[List[Union[int, Dict[str, List[int]]]]] = None,\n",
    "        activation_fn: Type[nn.Module] = nn.Tanh,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super(CustomActorCriticPolicy, self).__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            net_arch,\n",
    "            activation_fn,\n",
    "            # Pass remaining arguments to base class\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # Disable orthogonal initialization\n",
    "        self.ortho_init = False\n",
    "\n",
    "    def _build_mlp_extractor(self) -> None:\n",
    "        self.mlp_extractor = CustomNetwork(self.features_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3f6ca-f126-4bb2-8ef8-c48143f92a9c",
   "metadata": {},
   "source": [
    "## Creating the enviorment and declaring PPO model with custom LSTM net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865ee483-fac4-41d6-af53-c61ae912933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df=df,window_size = 30, frame_bound=(30,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "eeb036b1-df9a-4b0e-8973-3e32f63a23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved_models_N225')\n",
    "log_path = os.path.join('Training','Logs')\n",
    "eval_callback = EvalCallback(env, \n",
    "                             eval_freq = 10000, \n",
    "                             verbose = 1, \n",
    "                             best_model_save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "13c75790-7ff8-4346-9ed8-4b7399e4df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ef90a94-124b-498c-a2df-d0cced776806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58879728"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(customLSTM(16*30,1024,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da84a5d-b69d-49ed-8bfa-7d8325001876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 290  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 44            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9755738e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.949         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.71e+15      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.000114     |\n",
      "|    value_loss           | 1.2e+16       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.96e+03      |\n",
      "|    ep_rew_mean          | -7.53e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 72            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 85            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2341974e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.956         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.21e+17      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | 2.04e-05      |\n",
      "|    value_loss           | 7.29e+17      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.96e+03      |\n",
      "|    ep_rew_mean          | -7.53e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 66            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018076718 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.924         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.35e+17      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | 0.000234      |\n",
      "|    value_loss           | 1.08e+18      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.96e+03     |\n",
      "|    ep_rew_mean          | -3.13e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.360898e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04e+16     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -5.67e-05    |\n",
      "|    value_loss           | 2.51e+16     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.96e+03      |\n",
      "|    ep_rew_mean          | -3.13e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 62            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 196           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.7914785e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.914         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.29e+18      |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | 0.000141      |\n",
      "|    value_loss           | 1.33e+19      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.96e+03      |\n",
      "|    ep_rew_mean          | -3.13e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 61            |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 232           |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2600969e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.949         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.49e+15      |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | 4.99e-06      |\n",
      "|    value_loss           | 1.28e+16      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.96e+03      |\n",
      "|    ep_rew_mean          | -2.19e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 60            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 270           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0815357e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.949         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.01e+18      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | 1.27e-05      |\n",
      "|    value_loss           | 3.34e+18      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.96e+03      |\n",
      "|    ep_rew_mean          | -2.19e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 60            |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 306           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020224991 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.911         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.72e+16      |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000494     |\n",
      "|    value_loss           | 8.88e+16      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = PPO(CustomActorCriticPolicy, env, verbose=1)#,tensorboard_log = log_path)\n",
    "\n",
    "%time model.learn(50000)#,callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54723d2-1c6e-48e7-b38b-0727e40c25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df = df, frame_bound=(30,5000), window_size = 30)\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    # obs = obs[np.newaxis, ...]\n",
    "    # print(obs.shape)\n",
    "    action, _states = model.predict(obs)\n",
    "    obs,rewards,done,info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\",info)\n",
    "        break\n",
    "        \n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7057e-ce76-4943-a24e-45ac157dcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df = df, frame_bound=(5020,5300), window_size = 30)\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    # obs = obs[np.newaxis, ...]\n",
    "    # print(obs.shape)\n",
    "    action, _states = model.predict(obs)\n",
    "    obs,rewards,done,info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\",info)\n",
    "        break\n",
    "        \n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efdcfb-fa41-493c-b2a9-fae7e000b6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7f426-ab03-4ae4-a690-6abe34f4de29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
