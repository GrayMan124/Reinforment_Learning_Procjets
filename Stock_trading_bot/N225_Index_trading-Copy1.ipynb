{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e70cf1a-6fb9-43b7-b884-00ce34b62d62",
   "metadata": {},
   "source": [
    "# N225 Japan Index trading "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187eb5dd-4fe5-4f9b-b23e-15273cfdb121",
   "metadata": {},
   "source": [
    "### Import dependecies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2029dffa-3829-4442-841f-b860ba9b96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_anytrading\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "from finta import TA\n",
    "from gym_anytrading.envs import StocksEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "import os\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecc96a-7a2e-45b5-83b2-285b0856d2f0",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749a14df-29ec-4983-9be9-ecd85c46711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/N225.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed33073-8300-4252-b41b-63f02fe4c9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5711, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73781f8c-b131-4324-8771-8061e8de2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df['RSI'] = TA.RSI(df)\n",
    "df['SMA'] = TA.SMA(df,14)\n",
    "df['ATR'] = TA.ATR(df)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33957c4a-a08c-4bb9-a757-7c1f1546f86f",
   "metadata": {},
   "source": [
    "### Creating my enviorment for AnyTrading, such that I can use 3 positions as actions (Short, Hold, Long) \n",
    "\n",
    "Here is the stanrd implementation of TradingEnv, I'm adding just the hold position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51cf3730-ef68-4a55-9a40-6e1309d3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(Enum):\n",
    "    Sell = 0\n",
    "    Hold = 1\n",
    "    Buy = 2\n",
    "\n",
    "\n",
    "class Positions(Enum):\n",
    "    Short = 0\n",
    "    Hold = 1\n",
    "    Long = 2\n",
    "    \n",
    "\n",
    "def opposite(position: Positions , action: int) -> any:\n",
    "    '''New opposite, so that it works with 3 actions, overwiev:\n",
    "            When action is Sell, we either Go to Hold (when we bought earlier) or short (when position was flat before)\n",
    "            \n",
    "            When action is Buy, we conduct the same reasoning but in the oppiste way\n",
    "\n",
    "            When the action is Hold we stay at current position\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    action = Actions(action)\n",
    "    if action == Actions.Sell:\n",
    "            \n",
    "        if position == Positions.Long:\n",
    "            return Positions.Hold, False\n",
    "        \n",
    "        if position == Positions.Hold:\n",
    "            return Positions.Short, True\n",
    "        \n",
    "        \n",
    "    if action == Actions.Buy:\n",
    "        if position == Positions.Short:\n",
    "            return Positions.Hold, False\n",
    "        \n",
    "        if position == Positions.Hold:\n",
    "            return Positions.Long, True\n",
    "        \n",
    "    return position, False\n",
    "        \n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df, window_size):\n",
    "        assert df.ndim == 2\n",
    "\n",
    "        self.seed()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        self.shape = (window_size, self.signal_features.shape[1])\n",
    "\n",
    "        # spaces\n",
    "        self.action_space = spaces.Discrete(len(Actions))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float64)\n",
    "\n",
    "        # episode\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.prices) - 1\n",
    "        self._done = None\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self._position = None\n",
    "        self._position_history = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        self._first_rendering = None\n",
    "        self.history = None\n",
    "\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self._done = False\n",
    "        self._current_tick = self._start_tick\n",
    "        self._last_trade_tick = self._current_tick - 1\n",
    "        self._position = Positions.Hold\n",
    "        self._position_history = (self.window_size * [None]) + [self._position]\n",
    "        self._total_reward = 0.\n",
    "        self._total_profit = 1.  # unit\n",
    "        self._first_rendering = True\n",
    "        self.history = {}\n",
    "        return self._get_observation()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        self._done = False\n",
    "        self._current_tick += 1\n",
    "\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._done = True\n",
    "\n",
    "        step_reward = self._calculate_reward(action)\n",
    "        self._total_reward += step_reward\n",
    "\n",
    "        self._update_profit(action)\n",
    "\n",
    "        self._position, trade = opposite(self._position, action)\n",
    "        if trade:\n",
    "            self._last_trade_tick = self._current_tick\n",
    "\n",
    "        self._position_history.append(self._position)\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "            position = self._position.value\n",
    "        )\n",
    "        self._update_history(info)\n",
    "\n",
    "        return observation, step_reward, self._done, info\n",
    "\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return self.signal_features[(self._current_tick-self.window_size+1):self._current_tick+1]\n",
    "\n",
    "\n",
    "    def _update_history(self, info):\n",
    "        if not self.history:\n",
    "            self.history = {key: [] for key in info.keys()}\n",
    "\n",
    "        for key, value in info.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "\n",
    "        def _plot_position(position, tick):\n",
    "            color = None\n",
    "            if position == Positions.Short:\n",
    "                color = 'red'\n",
    "            elif position == Positions.Long:\n",
    "                color = 'green'\n",
    "            elif position == Positions.Hold:\n",
    "                color = 'blue'\n",
    "            if color:\n",
    "                plt.scatter(tick, self.prices[tick], color=color)\n",
    "\n",
    "        if self._first_rendering:\n",
    "            self._first_rendering = False\n",
    "            plt.cla()\n",
    "            plt.plot(self.prices)\n",
    "            start_position = self._position_history[self._start_tick]\n",
    "            _plot_position(start_position, self._start_tick)\n",
    "\n",
    "        _plot_position(self._position, self._current_tick)\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "\n",
    "        plt.pause(0.01)\n",
    "\n",
    "\n",
    "    def render_all(self, mode='human'):\n",
    "        window_ticks = np.arange(len(self._position_history))\n",
    "        plt.plot(self.prices)\n",
    "\n",
    "        short_ticks = []\n",
    "        long_ticks = []\n",
    "        hold_ticks = [] \n",
    "        for i, tick in enumerate(window_ticks):\n",
    "            if self._position_history[i] == Positions.Short:\n",
    "                short_ticks.append(tick)\n",
    "            elif self._position_history[i] == Positions.Long:\n",
    "                long_ticks.append(tick)\n",
    "            elif self._position_history[i] == Positions.Hold:\n",
    "                hold_ticks.append(tick)\n",
    "\n",
    "        plt.plot(short_ticks, self.prices[short_ticks], 'ro')\n",
    "        plt.plot(hold_ticks, self.prices[hold_ticks], 'bo')\n",
    "        plt.plot(long_ticks, self.prices[long_ticks], 'go')\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def close(self):\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def save_rendering(self, filepath):\n",
    "        plt.savefig(filepath)\n",
    "\n",
    "\n",
    "    def pause_rendering(self):\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def _process_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def max_possible_profit(self):  # trade fees are ignored\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e81940-10c9-458f-86a0-3bc0cc57b5a1",
   "metadata": {},
   "source": [
    "#### StocksEnv\n",
    "\n",
    "Here I'm implementing StocksEnv such that it'll utilize Hold action also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0c1ffb-aaae-40b4-aa61-57bd3dff8bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .trading_env import TradingEnv, Actions, Positions\n",
    "\n",
    "\n",
    "class StocksEnv(TradingEnv):\n",
    "\n",
    "    def __init__(self, df, window_size, frame_bound):\n",
    "        assert len(frame_bound) == 2\n",
    "\n",
    "        self.frame_bound = frame_bound\n",
    "        super().__init__(df, window_size)\n",
    "\n",
    "        self.trade_fee_bid_percent = 0.003  # unit\n",
    "        self.trade_fee_ask_percent = 0.003\n",
    "        # # unit\n",
    "        \n",
    "        # self.trade_fee_bid_percent = 0  # unit\n",
    "        # self.trade_fee_ask_percent = 0\n",
    "    def _process_data(self):\n",
    "        start = self.frame_bound[0] - self.window_size\n",
    "        end = self.frame_bound[1]\n",
    "        prices = self.df.loc[:,'Low'].to_numpy()[start:end]\n",
    "        signal_features = self.df.loc[:,['Low','Volume','SMA','RSI','ATR']].to_numpy()[start:end]\n",
    "        return prices, signal_features\n",
    "    \n",
    "#     def _process_data(self):\n",
    "#         prices = self.df.loc[:, 'Close'].to_numpy()\n",
    "\n",
    "#         prices[self.frame_bound[0] - self.window_size]  # validate index (TODO: Improve validation)\n",
    "#         prices = prices[self.frame_bound[0]-self.window_size:self.frame_bound[1]]\n",
    "\n",
    "#         diff = np.insert(np.diff(prices), 0, 0)\n",
    "#         signal_features = np.column_stack((prices, diff))\n",
    "\n",
    "#         return prices, signal_features\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        step_reward = 0\n",
    "        trade = True\n",
    "\n",
    "        if trade:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "            price_diff = current_price - last_trade_price\n",
    "\n",
    "            if self._position == Positions.Long:\n",
    "                step_reward += price_diff\n",
    "            elif self._position == Positions.Short:\n",
    "                step_reward += -price_diff \n",
    "\n",
    "        return step_reward\n",
    "\n",
    "    \n",
    "# Is this actually correct? reutrn for short shuld be different I suppouse\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        trade = True\n",
    "        \n",
    "        if trade or self._done:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "\n",
    "            if self._position == Positions.Long:\n",
    "                shares = (self._total_profit * (1 - self.trade_fee_ask_percent)) / last_trade_price\n",
    "                self._total_profit = (shares * (1 - self.trade_fee_bid_percent)) * current_price\n",
    "            elif self._position == Positions.Short:\n",
    "                self._total_profit = (self._total_profit *(1 + (last_trade_price - current_price - self.trade_fee_bid_percent*last_trade_price - self.trade_fee_ask_percent*current_price ) / last_trade_price))\n",
    "\n",
    "    def max_possible_profit(self):\n",
    "        current_tick = self._start_tick\n",
    "        last_trade_tick = current_tick - 1\n",
    "        profit = 1.\n",
    "\n",
    "        while current_tick <= self._end_tick:\n",
    "            position = None\n",
    "            if self.prices[current_tick] < self.prices[current_tick - 1]:\n",
    "                while (current_tick <= self._end_tick and\n",
    "                       self.prices[current_tick] < self.prices[current_tick - 1]):\n",
    "                    current_tick += 1\n",
    "                position = Positions.Short\n",
    "            else:\n",
    "                while (current_tick <= self._end_tick and\n",
    "                       self.prices[current_tick] >= self.prices[current_tick - 1]):\n",
    "                    current_tick += 1\n",
    "                position = Positions.Long\n",
    "\n",
    "            if position == Positions.Long:\n",
    "                current_price = self.prices[current_tick - 1]\n",
    "                last_trade_price = self.prices[last_trade_tick]\n",
    "                shares = profit / last_trade_price\n",
    "                profit = shares * current_price\n",
    "            last_trade_tick = current_tick - 1\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa945f-b4de-4a0c-91dc-c220fa5d9891",
   "metadata": {},
   "source": [
    "### Testing the enviorment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8e1181-5e27-4bac-8505-bd96a58122db",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df=df,window_size = 9, frame_bound=(9,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5769a15-dd84-44c2-9f48-755ae4f2e7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info {'total_reward': 1287.720704000003, 'total_profit': 1.0230795917425752, 'position': 0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    # action = 0\n",
    "    # print(n_state.shape)\n",
    "    n_state, reward,done, info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\", info)\n",
    "        \n",
    "        break\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3acd3ea-1e79-4ca3-b10f-07ec2a846ea3",
   "metadata": {},
   "source": [
    "## Creating custom LSTM model for trading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4704e6-5e20-48d1-aa5a-b0fe799e6059",
   "metadata": {},
   "source": [
    "I create this custom model, becouse I assume, LSTM will work better then normal Neural net. \n",
    "\n",
    " Architecture of this model may change, depending on the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcad7d4a-8fc6-416e-8c48-a07d99c72b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLSTM(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm=nn.LSTM(input_size,hidden_size,num_layers=2,bidirectional= True)#,batch_first=True)\n",
    "        self.fully_connected=nn.Sequential(\n",
    "            nn.Linear(hidden_size*2,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512,756),\n",
    "            nn.BatchNorm1d(756),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(756,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        batch_size=x.shape[0]\n",
    "        h0=torch.zeros(2*2,self.hidden_size)\n",
    "        c0=torch.zeros(2*2,self.hidden_size)\n",
    "\n",
    "        lstm_output, cels = self.lstm(x,(h0,c0))\n",
    "        flatten_output=torch.flatten(lstm_output,start_dim=1)\n",
    "        \n",
    "        output=self.fully_connected(flatten_output)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8040b17-f2df-46af-8b73-3bf55e841bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "\n",
    "class CustomNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom network for policy and value function.\n",
    "    It receives as input the features extracted by the feature extractor.\n",
    "\n",
    "    :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN)\n",
    "    :param last_layer_dim_pi: (int) number of units for the last layer of the policy network\n",
    "    :param last_layer_dim_vf: (int) number of units for the last layer of the value network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim: int,\n",
    "        last_layer_dim_pi: int = 128,\n",
    "        last_layer_dim_vf: int = 128,\n",
    "    ):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "\n",
    "        # IMPORTANT:\n",
    "        # Save output dimensions, used to create the distributions\n",
    "        self.latent_dim_pi = last_layer_dim_pi\n",
    "        self.latent_dim_vf = last_layer_dim_vf\n",
    "\n",
    "        # Policy network\n",
    "        # self.policy_net = nn.Sequential(\n",
    "        #     nn.Linear(feature_dim, last_layer_dim_pi), nn.ReLU()\n",
    "        # )\n",
    "        \n",
    "        self.policy_net = customLSTM(feature_dim,64,last_layer_dim_pi)\n",
    "        \n",
    "        # Value network\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(128,256), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(128,last_layer_dim_vf), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, features: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
    "        \"\"\"\n",
    "        :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network.\n",
    "            If all layers are shared, then ``latent_policy == latent_value``\n",
    "        \"\"\"\n",
    "        return self.policy_net(features), self.value_net(features)\n",
    "\n",
    "    def forward_actor(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.policy_net(features)\n",
    "\n",
    "    def forward_critic(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.value_net(features)\n",
    "\n",
    "\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: gym.spaces.Space,\n",
    "        action_space: gym.spaces.Space,\n",
    "        lr_schedule: Callable[[float], float],\n",
    "        net_arch: Optional[List[Union[int, Dict[str, List[int]]]]] = None,\n",
    "        activation_fn: Type[nn.Module] = nn.Tanh,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super(CustomActorCriticPolicy, self).__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            net_arch,\n",
    "            activation_fn,\n",
    "            # Pass remaining arguments to base class\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # Disable orthogonal initialization\n",
    "        self.ortho_init = False\n",
    "\n",
    "    def _build_mlp_extractor(self) -> None:\n",
    "        self.mlp_extractor = CustomNetwork(self.features_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3f6ca-f126-4bb2-8ef8-c48143f92a9c",
   "metadata": {},
   "source": [
    "## Creating the enviorment and declaring PPO model with custom LSTM net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "865ee483-fac4-41d6-af53-c61ae912933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df=df,window_size = 15, frame_bound=(15,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb036b1-df9a-4b0e-8973-3e32f63a23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved_models_N225')\n",
    "log_path = os.path.join('Training','Logs')\n",
    "eval_callback = EvalCallback(env, \n",
    "                             eval_freq = 10000, \n",
    "                             verbose = 1, \n",
    "                             best_model_save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da84a5d-b69d-49ed-8bfa-7d8325001876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\416569\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 233  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 8    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 38           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.563363e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.51e+11     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | 0.000433     |\n",
      "|    value_loss           | 2.34e+12     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 3.99e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 31            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 196           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0818552e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.417         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.23e+12      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -9.03e-05     |\n",
      "|    value_loss           | 2.64e+12      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 3.99e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 283           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4684618e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.836         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.77e+11      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -2.94e-05     |\n",
      "|    value_loss           | 4.48e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 8.61e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 364           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2065215e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.543         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.24e+11      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000123     |\n",
      "|    value_loss           | 7.13e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 8.61e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 26            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 467           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8256571e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.831         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.78e+11      |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.000172     |\n",
      "|    value_loss           | 5.44e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.98e+03     |\n",
      "|    ep_rew_mean          | 8.61e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 26           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 547          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.782435e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.869        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.23e+10     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -7.98e-05    |\n",
      "|    value_loss           | 2.03e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 1.57e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 26            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 616           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1646352e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.51          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.01e+11      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -9.55e-05     |\n",
      "|    value_loss           | 3.33e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 1.57e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 26            |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 685           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5547168e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.856         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.5e+10       |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | 1.04e-05      |\n",
      "|    value_loss           | 8.05e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 751           |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2767606e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.475         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.25e+10      |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -8.04e-05     |\n",
      "|    value_loss           | 1.39e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 812           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2331602e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.883         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.58e+10      |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | 0.000159      |\n",
      "|    value_loss           | 4.39e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 878           |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2737018e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.766         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.38e+10      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | 2.85e-06      |\n",
      "|    value_loss           | 3.37e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.96e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 942           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9131228e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.69          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.92e+10      |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.000113     |\n",
      "|    value_loss           | 4.08e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.96e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 1007          |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4348265e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.779         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.38e+09      |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.000116     |\n",
      "|    value_loss           | 1.1e+10       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.09e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 1070          |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1662796e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.302         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.13e+09      |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -9.56e-05     |\n",
      "|    value_loss           | 2.14e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.09e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 1137          |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5548477e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.8           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.49e+09      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -1.9e-05      |\n",
      "|    value_loss           | 4.92e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.09e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 29            |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 1199          |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1437503e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.645         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.36e+09      |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | 9.56e-05      |\n",
      "|    value_loss           | 4.35e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.49e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 29            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 1263          |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8438615e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.766         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.89e+09      |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -3.31e-06     |\n",
      "|    value_loss           | 4.1e+09       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.49e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 29            |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 1329          |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1798798e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.761         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.84e+08      |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000127     |\n",
      "|    value_loss           | 1.35e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.04e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 29            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 1392          |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3703557e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.271         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.29e+08      |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000121     |\n",
      "|    value_loss           | 2.42e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.04e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 29            |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 1456          |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4094334e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.616         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.53e+08      |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | 5.17e-05      |\n",
      "|    value_loss           | 5.41e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98e+03      |\n",
      "|    ep_rew_mean          | 2.06e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 29            |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 1521          |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1925778e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.372         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.56e+08      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | 0.000104      |\n",
      "|    value_loss           | 6.01e+08      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = PPO(CustomActorCriticPolicy, env, verbose=1)#,tensorboard_log = log_path)\n",
    "model.learn(100000)#,callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54723d2-1c6e-48e7-b38b-0727e40c25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df = df, frame_bound=(15,4998), window_size = 15)\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    # obs = obs[np.newaxis, ...]\n",
    "    # print(obs.shape)\n",
    "    action, _states = model.predict(obs)\n",
    "    obs,rewards,done,info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\",info)\n",
    "        break\n",
    "        \n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7057e-ce76-4943-a24e-45ac157dcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df = df, frame_bound=(5000,5400), window_size = 15)\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    # obs = obs[np.newaxis, ...]\n",
    "    # print(obs.shape)\n",
    "    action, _states = model.predict(obs)\n",
    "    obs,rewards,done,info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\",info)\n",
    "        break\n",
    "        \n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efdcfb-fa41-493c-b2a9-fae7e000b6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7f426-ab03-4ae4-a690-6abe34f4de29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
