{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e70cf1a-6fb9-43b7-b884-00ce34b62d62",
   "metadata": {},
   "source": [
    "# N225 Japan Index trading\n",
    "\n",
    "### Due to CUDA support I'm editing this notebook at google colab - I'll refresh this notebook when I'll get some results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187eb5dd-4fe5-4f9b-b23e-15273cfdb121",
   "metadata": {},
   "source": [
    "### Import dependecies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2029dffa-3829-4442-841f-b860ba9b96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_anytrading\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "from finta import TA\n",
    "from gym_anytrading.envs import StocksEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "import os\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecc96a-7a2e-45b5-83b2-285b0856d2f0",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749a14df-29ec-4983-9be9-ecd85c46711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/N225.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed33073-8300-4252-b41b-63f02fe4c9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5711, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73781f8c-b131-4324-8771-8061e8de2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df['RSI'] = TA.RSI(df)\n",
    "df['SMA'] = TA.SMA(df,14)\n",
    "df['ATR'] = TA.ATR(df)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33957c4a-a08c-4bb9-a757-7c1f1546f86f",
   "metadata": {},
   "source": [
    "### Creating my enviorment for AnyTrading, such that I can use 3 positions as actions (Short, Hold, Long) \n",
    "\n",
    "Here is the stanrd implementation of TradingEnv, I'm adding just the hold position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51cf3730-ef68-4a55-9a40-6e1309d3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(Enum):\n",
    "    Sell = 0\n",
    "    Hold = 1\n",
    "    Buy = 2\n",
    "\n",
    "\n",
    "class Positions(Enum):\n",
    "    Short = 0\n",
    "    Hold = 1\n",
    "    Long = 2\n",
    "    \n",
    "\n",
    "def opposite(position: Positions , action: int) -> any:\n",
    "    '''New opposite, so that it works with 3 actions, overwiev:\n",
    "            When action is Sell, we either Go to Hold (when we bought earlier) or short (when position was flat before)\n",
    "            \n",
    "            When action is Buy, we conduct the same reasoning but in the oppiste way\n",
    "\n",
    "            When the action is Hold we stay at current position\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    action = Actions(action)\n",
    "    if action == Actions.Sell:\n",
    "            \n",
    "        if position == Positions.Long:\n",
    "            return Positions.Hold, False\n",
    "        \n",
    "        if position == Positions.Hold:\n",
    "            return Positions.Short, True\n",
    "        \n",
    "        \n",
    "    if action == Actions.Buy:\n",
    "        if position == Positions.Short:\n",
    "            return Positions.Hold, False\n",
    "        \n",
    "        if position == Positions.Hold:\n",
    "            return Positions.Long, True\n",
    "        \n",
    "    return position, False\n",
    "        \n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df, window_size):\n",
    "        assert df.ndim == 2\n",
    "\n",
    "        self.seed()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        self.shape = (window_size, self.signal_features.shape[1])\n",
    "\n",
    "        # spaces\n",
    "        self.action_space = spaces.Discrete(len(Actions))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float64)\n",
    "\n",
    "        # episode\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.prices) - 1\n",
    "        self._done = None\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self._position = None\n",
    "        self._position_history = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        self._first_rendering = None\n",
    "        self.history = None\n",
    "\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self._done = False\n",
    "        self._current_tick = self._start_tick\n",
    "        self._last_trade_tick = self._current_tick - 1\n",
    "        self._position = Positions.Hold\n",
    "        self._position_history = (self.window_size * [None]) + [self._position]\n",
    "        self._total_reward = 0.\n",
    "        self._total_profit = 1.  # unit\n",
    "        self._first_rendering = True\n",
    "        self.history = {}\n",
    "        return self._get_observation()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        self._done = False\n",
    "        self._current_tick += 1\n",
    "\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._done = True\n",
    "\n",
    "        step_reward = self._calculate_reward(action)\n",
    "        self._total_reward += step_reward\n",
    "\n",
    "        self._update_profit(action)\n",
    "\n",
    "        self._position, trade = opposite(self._position, action)\n",
    "        if trade:\n",
    "            self._last_trade_tick = self._current_tick\n",
    "\n",
    "        self._position_history.append(self._position)\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "            position = self._position.value\n",
    "        )\n",
    "        self._update_history(info)\n",
    "\n",
    "        return observation, step_reward, self._done, info\n",
    "\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return self.signal_features[(self._current_tick-self.window_size+1):self._current_tick+1]\n",
    "\n",
    "\n",
    "    def _update_history(self, info):\n",
    "        if not self.history:\n",
    "            self.history = {key: [] for key in info.keys()}\n",
    "\n",
    "        for key, value in info.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "\n",
    "        def _plot_position(position, tick):\n",
    "            color = None\n",
    "            if position == Positions.Short:\n",
    "                color = 'red'\n",
    "            elif position == Positions.Long:\n",
    "                color = 'green'\n",
    "            elif position == Positions.Hold:\n",
    "                color = 'blue'\n",
    "            if color:\n",
    "                plt.scatter(tick, self.prices[tick], color=color)\n",
    "\n",
    "        if self._first_rendering:\n",
    "            self._first_rendering = False\n",
    "            plt.cla()\n",
    "            plt.plot(self.prices)\n",
    "            start_position = self._position_history[self._start_tick]\n",
    "            _plot_position(start_position, self._start_tick)\n",
    "\n",
    "        _plot_position(self._position, self._current_tick)\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "\n",
    "        plt.pause(0.01)\n",
    "\n",
    "\n",
    "    def render_all(self, mode='human'):\n",
    "        window_ticks = np.arange(len(self._position_history))\n",
    "        plt.plot(self.prices)\n",
    "\n",
    "        short_ticks = []\n",
    "        long_ticks = []\n",
    "        hold_ticks = [] \n",
    "        for i, tick in enumerate(window_ticks):\n",
    "            if self._position_history[i] == Positions.Short:\n",
    "                short_ticks.append(tick)\n",
    "            elif self._position_history[i] == Positions.Long:\n",
    "                long_ticks.append(tick)\n",
    "            elif self._position_history[i] == Positions.Hold:\n",
    "                hold_ticks.append(tick)\n",
    "\n",
    "        plt.plot(short_ticks, self.prices[short_ticks], 'ro')\n",
    "        plt.plot(hold_ticks, self.prices[hold_ticks], 'bo')\n",
    "        plt.plot(long_ticks, self.prices[long_ticks], 'go')\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def close(self):\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def save_rendering(self, filepath):\n",
    "        plt.savefig(filepath)\n",
    "\n",
    "\n",
    "    def pause_rendering(self):\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def _process_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def max_possible_profit(self):  # trade fees are ignored\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e81940-10c9-458f-86a0-3bc0cc57b5a1",
   "metadata": {},
   "source": [
    "#### StocksEnv\n",
    "\n",
    "Here I'm implementing StocksEnv such that it'll utilize Hold action also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0c1ffb-aaae-40b4-aa61-57bd3dff8bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .trading_env import TradingEnv, Actions, Positions\n",
    "\n",
    "\n",
    "class StocksEnv(TradingEnv):\n",
    "\n",
    "    def __init__(self, df, window_size, frame_bound):\n",
    "        assert len(frame_bound) == 2\n",
    "\n",
    "        self.frame_bound = frame_bound\n",
    "        super().__init__(df, window_size)\n",
    "\n",
    "        self.trade_fee_bid_percent = 0.003  # unit\n",
    "        self.trade_fee_ask_percent = 0.003\n",
    "        # # unit\n",
    "        \n",
    "        # self.trade_fee_bid_percent = 0  # unit\n",
    "        # self.trade_fee_ask_percent = 0\n",
    "    def _process_data(self):\n",
    "        start = self.frame_bound[0] - self.window_size\n",
    "        end = self.frame_bound[1]\n",
    "        prices = self.df.loc[:,'Low'].to_numpy()[start:end]\n",
    "        signal_features = self.df.loc[:,['Low','Volume','SMA','RSI','ATR']].to_numpy()[start:end]\n",
    "        return prices, signal_features\n",
    "    \n",
    "#     def _process_data(self):\n",
    "#         prices = self.df.loc[:, 'Close'].to_numpy()\n",
    "\n",
    "#         prices[self.frame_bound[0] - self.window_size]  # validate index (TODO: Improve validation)\n",
    "#         prices = prices[self.frame_bound[0]-self.window_size:self.frame_bound[1]]\n",
    "\n",
    "#         diff = np.insert(np.diff(prices), 0, 0)\n",
    "#         signal_features = np.column_stack((prices, diff))\n",
    "\n",
    "#         return prices, signal_features\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        step_reward = 0\n",
    "        trade = True\n",
    "\n",
    "        if trade:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "            price_diff = current_price - last_trade_price\n",
    "\n",
    "            if self._position == Positions.Long:\n",
    "                step_reward += price_diff\n",
    "            elif self._position == Positions.Short:\n",
    "                step_reward += -price_diff \n",
    "\n",
    "        return step_reward\n",
    "\n",
    "    \n",
    "# Is this actually correct? reutrn for short shuld be different I suppouse\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        trade = True\n",
    "        \n",
    "        if trade or self._done:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "\n",
    "            if self._position == Positions.Long:\n",
    "                shares = (self._total_profit * (1 - self.trade_fee_ask_percent)) / last_trade_price\n",
    "                self._total_profit = (shares * (1 - self.trade_fee_bid_percent)) * current_price\n",
    "            elif self._position == Positions.Short:\n",
    "                self._total_profit = (self._total_profit *(1 + (last_trade_price - current_price - self.trade_fee_bid_percent*last_trade_price - self.trade_fee_ask_percent*current_price ) / last_trade_price))\n",
    "\n",
    "    def max_possible_profit(self):\n",
    "        current_tick = self._start_tick\n",
    "        last_trade_tick = current_tick - 1\n",
    "        profit = 1.\n",
    "\n",
    "        while current_tick <= self._end_tick:\n",
    "            position = None\n",
    "            if self.prices[current_tick] < self.prices[current_tick - 1]:\n",
    "                while (current_tick <= self._end_tick and\n",
    "                       self.prices[current_tick] < self.prices[current_tick - 1]):\n",
    "                    current_tick += 1\n",
    "                position = Positions.Short\n",
    "            else:\n",
    "                while (current_tick <= self._end_tick and\n",
    "                       self.prices[current_tick] >= self.prices[current_tick - 1]):\n",
    "                    current_tick += 1\n",
    "                position = Positions.Long\n",
    "\n",
    "            if position == Positions.Long:\n",
    "                current_price = self.prices[current_tick - 1]\n",
    "                last_trade_price = self.prices[last_trade_tick]\n",
    "                shares = profit / last_trade_price\n",
    "                profit = shares * current_price\n",
    "            last_trade_tick = current_tick - 1\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa945f-b4de-4a0c-91dc-c220fa5d9891",
   "metadata": {},
   "source": [
    "### Testing the enviorment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8e1181-5e27-4bac-8505-bd96a58122db",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df=df,window_size = 30, frame_bound=(9,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5769a15-dd84-44c2-9f48-755ae4f2e7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info {'total_reward': 45.77148499999748, 'total_profit': 0.9843222921305844, 'position': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    # action = 0\n",
    "    # print(n_state.shape)\n",
    "    n_state, reward,done, info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\", info)\n",
    "        \n",
    "        break\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3acd3ea-1e79-4ca3-b10f-07ec2a846ea3",
   "metadata": {},
   "source": [
    "## Creating custom LSTM model for trading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4704e6-5e20-48d1-aa5a-b0fe799e6059",
   "metadata": {},
   "source": [
    "I create this custom model, becouse I assume, LSTM will work better then normal Neural net. \n",
    "\n",
    " Architecture of this model may change, depending on the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcad7d4a-8fc6-416e-8c48-a07d99c72b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLSTM(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm=nn.LSTM(input_size,hidden_size,num_layers=1,bidirectional= True)#,batch_first=True)\n",
    "        self.fully_connected=nn.Sequential(\n",
    "            nn.Linear(hidden_size*2,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512,756),\n",
    "            nn.BatchNorm1d(756),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(756,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        batch_size=x.shape[0]\n",
    "        h0=torch.zeros(1*2,self.hidden_size)\n",
    "        c0=torch.zeros(1*2,self.hidden_size)\n",
    "\n",
    "        lstm_output, cels = self.lstm(x,(h0,c0))\n",
    "        flatten_output=torch.flatten(lstm_output,start_dim=1)\n",
    "        \n",
    "        output=self.fully_connected(flatten_output)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8040b17-f2df-46af-8b73-3bf55e841bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "\n",
    "class CustomNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom network for policy and value function.\n",
    "    It receives as input the features extracted by the feature extractor.\n",
    "\n",
    "    :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN)\n",
    "    :param last_layer_dim_pi: (int) number of units for the last layer of the policy network\n",
    "    :param last_layer_dim_vf: (int) number of units for the last layer of the value network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim: int,\n",
    "        last_layer_dim_pi: int = 128,\n",
    "        last_layer_dim_vf: int = 128,\n",
    "    ):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "\n",
    "        # IMPORTANT:\n",
    "        # Save output dimensions, used to create the distributions\n",
    "        self.latent_dim_pi = last_layer_dim_pi\n",
    "        self.latent_dim_vf = last_layer_dim_vf\n",
    "\n",
    "        # Policy network\n",
    "        # self.policy_net = nn.Sequential(\n",
    "        #     nn.Linear(feature_dim, last_layer_dim_pi), nn.ReLU()\n",
    "        # )\n",
    "        \n",
    "        self.policy_net = customLSTM(feature_dim,64,last_layer_dim_pi)\n",
    "        \n",
    "        # Value network\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(128,256), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), \n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(128,last_layer_dim_vf), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, features: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
    "        \"\"\"\n",
    "        :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network.\n",
    "            If all layers are shared, then ``latent_policy == latent_value``\n",
    "        \"\"\"\n",
    "        return self.policy_net(features), self.value_net(features)\n",
    "\n",
    "    def forward_actor(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.policy_net(features)\n",
    "\n",
    "    def forward_critic(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.value_net(features)\n",
    "\n",
    "\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: gym.spaces.Space,\n",
    "        action_space: gym.spaces.Space,\n",
    "        lr_schedule: Callable[[float], float],\n",
    "        net_arch: Optional[List[Union[int, Dict[str, List[int]]]]] = None,\n",
    "        activation_fn: Type[nn.Module] = nn.Tanh,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super(CustomActorCriticPolicy, self).__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            net_arch,\n",
    "            activation_fn,\n",
    "            # Pass remaining arguments to base class\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # Disable orthogonal initialization\n",
    "        self.ortho_init = False\n",
    "\n",
    "    def _build_mlp_extractor(self) -> None:\n",
    "        self.mlp_extractor = CustomNetwork(self.features_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3f6ca-f126-4bb2-8ef8-c48143f92a9c",
   "metadata": {},
   "source": [
    "## Creating the enviorment and declaring PPO model with custom LSTM net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "865ee483-fac4-41d6-af53-c61ae912933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df=df,window_size = 30, frame_bound=(30,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb036b1-df9a-4b0e-8973-3e32f63a23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved_models_N225')\n",
    "log_path = os.path.join('Training','Logs')\n",
    "eval_callback = EvalCallback(env, \n",
    "                             eval_freq = 10000, \n",
    "                             verbose = 1, \n",
    "                             best_model_save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9da84a5d-b69d-49ed-8bfa-7d8325001876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\416569\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 392  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 5    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.556336e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.32e+11     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | 1.99e-05     |\n",
      "|    value_loss           | 2.43e+12     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | -2.63e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 53            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 115           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5269936e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.389         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.99e+11      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | 4.33e-06      |\n",
      "|    value_loss           | 1.57e+12      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | -2.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.048082e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.61e+11     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000199    |\n",
      "|    value_loss           | 3.81e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 2.32e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 203           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5889615e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.668         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.91e+11      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | 9.16e-05      |\n",
      "|    value_loss           | 6.12e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 2.32e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 49            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 247           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5719928e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.853         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.79e+11      |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | 2.78e-05      |\n",
      "|    value_loss           | 3.24e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 2.32e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 291          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.593266e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+11     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | 5.64e-06     |\n",
      "|    value_loss           | 1.72e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 1.68e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 49            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 334           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6324862e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.585         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.61e+11      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | 8.45e-05      |\n",
      "|    value_loss           | 2.15e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 1.68e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 376          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.185487e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.16e+10     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | 8.05e-05     |\n",
      "|    value_loss           | 5.15e+10     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 1.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 49            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 417           |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6456936e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.499         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.28e+10      |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | 0.00019       |\n",
      "|    value_loss           | 9.29e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 1.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 48            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 468           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3682678e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.888         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+10      |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | 7.7e-05       |\n",
      "|    value_loss           | 2.35e+10      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 1.83e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 47           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 515          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.551886e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.792        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.37e+09     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -2.26e-05    |\n",
      "|    value_loss           | 1.16e+10     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 1.33e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 47            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 561           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6830425e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.779         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.24e+10      |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -9.17e-05     |\n",
      "|    value_loss           | 1.72e+10      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 1.33e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 617          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.918893e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.52e+09     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -8.99e-05    |\n",
      "|    value_loss           | 7.9e+09      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 5.03e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 668           |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5717436e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.48          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.08e+09      |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | 7.18e-05      |\n",
      "|    value_loss           | 1.1e+10       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 5.03e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 720          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.134343e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.02e+08     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | 0.000121     |\n",
      "|    value_loss           | 2.98e+09     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | -1.68e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 772           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5987287e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.692         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.97e+08      |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.000107     |\n",
      "|    value_loss           | 2.54e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | -1.68e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 823           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7453713e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.808         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.38e+08      |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | 6.94e-05      |\n",
      "|    value_loss           | 2.49e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | -1.68e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 874           |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0900101e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.899         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.7e+08       |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | 6.12e-05      |\n",
      "|    value_loss           | 6.85e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 2.59e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 922           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5768135e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.519         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.93e+08      |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -4.39e-05     |\n",
      "|    value_loss           | 1.42e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 2.59e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 975           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1032832e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.802         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.16e+08      |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | 5.22e-05      |\n",
      "|    value_loss           | 2.81e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 7.13e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 1029          |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5301484e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.775         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.34e+08      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | 7.54e-06      |\n",
      "|    value_loss           | 5.04e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 7.13e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 1082          |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5186688e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.859         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.71e+07      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.00012      |\n",
      "|    value_loss           | 2.04e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 7.13e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 1134          |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6730599e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.859         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.44e+07      |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -2.86e-05     |\n",
      "|    value_loss           | 9.37e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 1.14e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 1179          |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5720754e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.583         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.96e+07      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | 1.06e-06      |\n",
      "|    value_loss           | 1.39e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 1.14e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 1223          |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0299212e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.785         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.43e+06      |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.000212     |\n",
      "|    value_loss           | 3.19e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 9.62e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 1270          |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6458915e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.51          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.25e+07      |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | 7.8e-06       |\n",
      "|    value_loss           | 1.04e+08      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 9.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 1315         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.249111e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+07     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | 0.000275     |\n",
      "|    value_loss           | 2.49e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 9.62e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 1360          |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5717495e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.717         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.87e+06      |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | 7.26e-05      |\n",
      "|    value_loss           | 2.17e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 1.28e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 1406          |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7764076e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.738         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.68e+06      |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | 3.19e-05      |\n",
      "|    value_loss           | 4.24e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 1.28e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 1450          |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7029397e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.673         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.65e+06      |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -1.43e-05     |\n",
      "|    value_loss           | 9.48e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 9.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 1491         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.593589e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.151        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.3e+06      |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000109    |\n",
      "|    value_loss           | 1.29e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 9.05e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 1532          |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4887868e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.679         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4e+06         |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.00018      |\n",
      "|    value_loss           | 8.97e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 4.03e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 1574          |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5584315e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.39          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.38e+06      |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | 5.13e-05      |\n",
      "|    value_loss           | 7.36e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 4.03e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 1612          |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8010032e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.762         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.16e+06      |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | 2.23e-05      |\n",
      "|    value_loss           | 8.44e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 4.03e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 1650          |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0192645e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.714         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.66e+06      |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | 0.00012       |\n",
      "|    value_loss           | 4.66e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 5.28e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 1688          |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6235572e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.462         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.63e+06      |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | 6.29e-05      |\n",
      "|    value_loss           | 8.15e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 5.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 1726         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.295802e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.78e+06     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -4.51e-06    |\n",
      "|    value_loss           | 1.03e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 4.33e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 1764          |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5837199e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.307         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.79e+06      |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | 2.03e-05      |\n",
      "|    value_loss           | 3.8e+06       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 4.33e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 1802          |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5974645e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.397         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.62e+06      |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | 0.000231      |\n",
      "|    value_loss           | 5.3e+06       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.97e+03    |\n",
      "|    ep_rew_mean          | 4.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1845        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 1.63441e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.77e+06    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -3.48e-05   |\n",
      "|    value_loss           | 2.49e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 8.16e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 1886          |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7092505e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.212         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.77e+06      |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.000165     |\n",
      "|    value_loss           | 3.88e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 8.16e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 1928          |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0285242e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.231         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+06      |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -4.43e-05     |\n",
      "|    value_loss           | 4.76e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 6.72e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 1970          |\n",
      "|    total_timesteps      | 90112         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7328566e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | -0.153        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.27e+06      |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -2.82e-05     |\n",
      "|    value_loss           | 2.62e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.97e+03      |\n",
      "|    ep_rew_mean          | 6.72e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 2014          |\n",
      "|    total_timesteps      | 92160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3692282e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 0.0133        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.11e+06      |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -0.000114     |\n",
      "|    value_loss           | 2.74e+06      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.97e+03    |\n",
      "|    ep_rew_mean          | 6.72e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 2054        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008124071 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.7e+05     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 1.58e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.97e+03     |\n",
      "|    ep_rew_mean          | 6.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 2092         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077933604 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43e+06     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    value_loss           | 2.65e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.97e+03    |\n",
      "|    ep_rew_mean          | 6.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1           |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 97194       |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015093235 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+06    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.0132      |\n",
      "|    value_loss           | 4.01e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.97e+03    |\n",
      "|    ep_rew_mean          | 8.72e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1           |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 97238       |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009532911 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+06    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.000562   |\n",
      "|    value_loss           | 3.13e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1da86cb35e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(CustomActorCriticPolicy, env, verbose=1)#,tensorboard_log = log_path)\n",
    "model.learn(100000)#,callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54723d2-1c6e-48e7-b38b-0727e40c25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df = df, frame_bound=(30,4998), window_size = 30)\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    # obs = obs[np.newaxis, ...]\n",
    "    # print(obs.shape)\n",
    "    action, _states = model.predict(obs)\n",
    "    obs,rewards,done,info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\",info)\n",
    "        break\n",
    "        \n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7057e-ce76-4943-a24e-45ac157dcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StocksEnv(df = df, frame_bound=(5000,5400), window_size = 30)\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    # obs = obs[np.newaxis, ...]\n",
    "    # print(obs.shape)\n",
    "    action, _states = model.predict(obs)\n",
    "    obs,rewards,done,info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\",info)\n",
    "        break\n",
    "        \n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efdcfb-fa41-493c-b2a9-fae7e000b6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7f426-ab03-4ae4-a690-6abe34f4de29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
